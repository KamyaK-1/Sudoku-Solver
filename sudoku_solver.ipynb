{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "CrkTXMNiAStU"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import keras\n",
        "import keras.backend as K\n",
        "from keras.optimizers import Adam\n",
        "from keras.models import Sequential\n",
        "from keras.utils import Sequence\n",
        "from keras.layers import *\n",
        "import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3e1cgUNATNJ",
        "outputId": "0da048a9-cfb6-4b13-ee2a-e99e16966785"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "(100000, 2)\n"
          ]
        }
      ],
      "source": [
        "data = pd.read_csv(\"sudoku.csv\")\n",
        "data = pd.DataFrame({\"quizzes\": data[\"puzzle\"], \"solutions\": data[\"solution\"]})\n",
        "data = data.iloc[0:100000,:2]\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Basics of mnist and tensorflow \n",
        "mnist = tf.keras.datasets.mnist\n",
        "\n",
        "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
        "\n",
        "model1 = tf.keras.models.Sequential([\n",
        "  tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
        "  tf.keras.layers.Dense(128, activation='relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.Dense(10, activation='softmax')\n",
        "])\n",
        "\n",
        "model1.compile(optimizer='adam',\n",
        "  loss='sparse_categorical_crossentropy',\n",
        "  metrics=['accuracy'])\n",
        "\n",
        "model1.fit(x_train, y_train, epochs=5)\n",
        "model1.evaluate(x_test, y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "gDCbXMvZCsGE"
      },
      "outputs": [],
      "source": [
        "path = './'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "XEzCy7GcAlFs"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(Sequence):\n",
        "    def __init__(self, df, batch_size=16, subset=\"train\", shuffle=False, info={}):\n",
        "        super().__init__()\n",
        "        self.df = df\n",
        "        self.batch_size = batch_size\n",
        "        self.shuffle = shuffle\n",
        "        self.subset = subset\n",
        "        self.info = info\n",
        "        self.on_epoch_end()\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.df) / self.batch_size))\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.indexes = np.arange(len(self.df))\n",
        "        if self.shuffle:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        X = np.empty((self.batch_size, 9, 9, 1))\n",
        "        y = np.empty((self.batch_size, 81), dtype=int)  # Change label shape to (batch_size, 81)\n",
        "\n",
        "        indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
        "        for i, f in enumerate(self.df['quizzes'].iloc[indexes]):\n",
        "            self.info[index * self.batch_size + i] = f\n",
        "            X[i,] = (np.array(list(map(int, list(f)))).reshape((9, 9, 1)) / 9) - 0.5\n",
        "\n",
        "        if self.subset == 'train':\n",
        "            for i, f in enumerate(self.df['solutions'].iloc[indexes]):\n",
        "                self.info[index * self.batch_size + i] = f\n",
        "                y[i,] = np.array(list(map(int, list(f)))) - 1  # Shape (batch_size, 81)\n",
        "\n",
        "        if self.subset == 'train':\n",
        "            return X, y\n",
        "        else:\n",
        "            return X\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d_crx_5IAmcL",
        "outputId": "a627824e-002d-4c49-dbaa-ca55a40d8de2"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/layers/convolutional/base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        }
      ],
      "source": [
        "model = Sequential()\n",
        "\n",
        "model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same', input_shape=(9,9,1)))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(64, kernel_size=(3,3), activation='relu', padding='same'))\n",
        "model.add(BatchNormalization())\n",
        "model.add(Conv2D(128, kernel_size=(1,1), activation='relu', padding='same'))\n",
        "\n",
        "model.add(Flatten())\n",
        "model.add(Dense(81*9))\n",
        "model.add(Reshape((-1, 9)))\n",
        "model.add(Activation('softmax'))\n",
        "\n",
        "adam = keras.optimizers.Adam(learning_rate=.001)\n",
        "model.compile(loss='sparse_categorical_crossentropy', optimizer=adam, metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zJ3wb2MKAn0i",
        "outputId": "44160dd8-5a57-43bf-a764-7dbe45ce2489"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(640, 9, 9, 1)"
            ]
          },
          "execution_count": 42,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_idx = int(len(data)*0.95)\n",
        "data = data.sample(frac=1).reset_index(drop=True)\n",
        "training_generator = DataGenerator(data.iloc[:train_idx], subset = \"train\", batch_size=640)\n",
        "validation_generator = DataGenerator(data.iloc[train_idx:], subset = \"train\",  batch_size=640)\n",
        "training_generator.__getitem__(4)[0].shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "id": "unKWyGdjAu5j"
      },
      "outputs": [],
      "source": [
        "from keras.callbacks import Callback, ModelCheckpoint, ReduceLROnPlateau\n",
        "filepath1 = \"weights-improvement-{epoch:02d}-{val_accuracy:.2f}.keras\"\n",
        "filepath2 = \"best_weights.keras\"\n",
        "checkpoint1 = ModelCheckpoint(filepath1, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "checkpoint2 = ModelCheckpoint(filepath2, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n",
        "\n",
        "reduce_lr = ReduceLROnPlateau(\n",
        "    monitor='val_loss',\n",
        "    patience=3,\n",
        "    verbose=1,\n",
        "    min_lr=1e-6\n",
        ")\n",
        "callbacks_list = [checkpoint1,checkpoint2,reduce_lr]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZv16D8bC_4J",
        "outputId": "6b0bc216-84ef-425a-90f5-affcfb2732f3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m147/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.1667 - loss: 2.2731\n",
            "Epoch 1: val_accuracy improved from -inf to 0.12581, saving model to weights-improvement-01-0.13.keras\n",
            "\n",
            "Epoch 1: val_accuracy improved from -inf to 0.12581, saving model to best_weights.keras\n",
            "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 71ms/step - accuracy: 0.1675 - loss: 2.2694 - val_accuracy: 0.1258 - val_loss: 2.2707 - learning_rate: 0.0010\n"
          ]
        }
      ],
      "source": [
        "history = model.fit(training_generator, validation_data=validation_generator, epochs=1, verbose=1, callbacks=callbacks_list)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "F8drLp8ZDEq8"
      },
      "outputs": [],
      "source": [
        "model.load_weights('best_weights.keras')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "id": "fadoQax-GmP3"
      },
      "outputs": [],
      "source": [
        "def norm(a):\n",
        "    return (a/9)-.5\n",
        "\n",
        "def denorm(a):\n",
        "    return (a+.5)*9\n",
        "\n",
        "def inference_sudoku(sample):\n",
        "\n",
        "    '''\n",
        "        This function solve the sudoku by filling blank positions one by one.\n",
        "    '''\n",
        "\n",
        "    feat = sample\n",
        "\n",
        "    while(True):\n",
        "\n",
        "        out = model.predict(feat.reshape((1,9,9,1)))\n",
        "        out = out.squeeze()\n",
        "\n",
        "        pred = np.argmax(out, axis=1).reshape((9,9))+1\n",
        "        prob = np.around(np.max(out, axis=1).reshape((9,9)), 2)\n",
        "\n",
        "        feat = denorm(feat).reshape((9,9))\n",
        "        mask = (feat==0)\n",
        "\n",
        "        if(mask.sum()==0):\n",
        "            break\n",
        "\n",
        "        prob_new = prob*mask\n",
        "\n",
        "        ind = np.argmax(prob_new)\n",
        "        x, y = (ind//9), (ind%9)\n",
        "\n",
        "        val = pred[x][y]\n",
        "        feat[x][y] = val\n",
        "        feat = norm(feat)\n",
        "\n",
        "    return pred\n",
        "\n",
        "def test_accuracy(feats, labels):\n",
        "\n",
        "    correct = 0\n",
        "\n",
        "    for i,feat in enumerate(feats):\n",
        "\n",
        "        pred = inference_sudoku(feat)\n",
        "\n",
        "        true = labels[i].reshape((9,9))+1\n",
        "\n",
        "        if(abs(true - pred).sum()==0):\n",
        "            correct += 1\n",
        "\n",
        "    print(correct/feats.shape[0])\n",
        "\n",
        "def solve_sudoku(game):\n",
        "\n",
        "    game = game.replace('\\n', '')\n",
        "    game = game.replace(' ', '')\n",
        "    game = np.array([int(j) for j in game]).reshape((9,9,1))\n",
        "    game = norm(game)\n",
        "    game = inference_sudoku(game)\n",
        "    return game"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tEJLXf-kHcND",
        "outputId": "b1f678b5-a0b2-410f-d052-782879f518de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 636ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 24ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step\n",
            "solved puzzle:\n",
            "\n",
            "[[3 2 1 1 5 1 1 6 4]\n",
            " [8 1 1 2 5 5 2 6 4]\n",
            " [6 2 2 6 3 6 5 1 7]\n",
            " [2 4 1 6 6 1 7 1 1]\n",
            " [6 2 1 2 1 2 2 5 1]\n",
            " [2 6 1 2 6 1 4 4 1]\n",
            " [1 5 6 2 2 2 1 1 6]\n",
            " [2 2 3 5 1 6 2 2 2]\n",
            " [2 1 6 8 1 5 6 2 6]]\n"
          ]
        }
      ],
      "source": [
        "new_game = '''\n",
        "          0 0 0 0 0 0 0 0 0\n",
        "          0 0 0 0 0 0 0 0 0\n",
        "          0 0 0 0 0 0 0 0 0\n",
        "          0 0 0 0 0 0 0 0 0\n",
        "          0 0 0 0 0 0 0 0 0\n",
        "          0 0 0 0 0 0 0 0 0\n",
        "          0 0 0 0 0 0 0 0 0\n",
        "          0 0 0 0 0 0 0 0 0\n",
        "          0 0 0 0 0 0 0 0 0\n",
        "      '''\n",
        "\n",
        "game = '''\n",
        "          0 0 0 7 0 0 0 9 6\n",
        "          0 0 3 0 6 9 1 7 8\n",
        "          0 0 7 2 0 0 5 0 0\n",
        "          0 7 5 0 0 0 0 0 0\n",
        "          9 0 1 0 0 0 3 0 0\n",
        "          0 0 0 0 0 0 0 0 0\n",
        "          0 0 9 0 0 0 0 0 1\n",
        "          3 1 8 0 2 0 4 0 7\n",
        "          2 4 0 0 0 5 0 0 0\n",
        "      '''\n",
        "\n",
        "game = solve_sudoku(game)\n",
        "\n",
        "print('solved puzzle:\\n')\n",
        "print(game)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MgaiTgflHupQ"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
